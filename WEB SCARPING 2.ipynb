{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bff91d",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c493a6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
      "     ---------------------------------------- 9.5/9.5 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rehana\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Collecting typing_extensions>=4.9.0\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
      "     -------------------------------------- 467.7/467.7 kB 9.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rehana\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Collecting exceptiongroup\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rehana\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting attrs>=23.2.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna in c:\\users\\rehana\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting sniffio>=1.3.0\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rehana\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rehana\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rehana\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: typing_extensions, sniffio, h11, exceptiongroup, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.1.0\n",
      "    Uninstalling attrs-22.1.0:\n",
      "      Successfully uninstalled attrs-22.1.0\n",
      "Successfully installed attrs-23.2.0 exceptiongroup-1.2.1 h11-0.14.0 outcome-1.3.0.post0 selenium-4.21.0 sniffio-1.3.1 trio-0.25.1 trio-websocket-0.11.1 typing_extensions-4.11.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5882325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac44d1",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "search_box = driver.find_element_by_id(\"qsb-keyword\")\n",
    "search_box.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_button = driver.find_element_by_id(\"qsb-submit-btn\")\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "location_filter = driver.find_element_by_xpath(\"//label[@for='loc_jobs_location_Delhi/NCR']\")\n",
    "location_filter.click()\n",
    "\n",
    "salary_filter = driver.find_element_by_xpath(\"//label[@for='salary_range_3-6']\")\n",
    "salary_filter.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "jobs = []\n",
    "for i in range(1, 11):\n",
    "    job_title = driver.find_element_by_xpath(f\"//li[@class='jobsearch-SerpJobCard']//div[2]/a[1]\").get_attribute(\"title\")\n",
    "    job_location = driver.find_element_by_xpath(f\"//li[@class='jobsearch-SerpJobCard']//div[2]/div[1]/span[2]\").text\n",
    "    company_name = driver.find_element_by_xpath(f\"//li[@class='jobsearch-SerpJobCard']//div[2]/div[1]/span[1]/a\").text\n",
    "    experience_required = driver.find_element_by_xpath(f\"//li[@class='jobsearch-SerpJobCard']//div[2]/div[2]/div/span\").text\n",
    "    jobs.append({'Job Title': job_title, 'Job Location': job_location, 'Company Name': company_name, 'Experience Required': experience_required})\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(jobs)\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e8061",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c37cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "job_title_field = driver.find_element_by_id(\"jobTitle\")\n",
    "job_title_field.send_keys(\"Data Scientist\")\n",
    "\n",
    "location_field = driver.find_element_by_id(\"location\")\n",
    "location_field.send_keys(\"Bangalore\")\n",
    "\n",
    "search_button = driver.find_element_by_id(\"searchBtn\")\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "jobs = []\n",
    "for i in range(1, 11):\n",
    "    job_title = driver.find_element_by_xpath(f\"//div[@class='jobsearch-SerpJobCard']//div[2]/a\").text\n",
    "    job_location = driver.find_element_by_xpath(f\"//div[@class='jobsearch-SerpJobCard']//div[3]/div[2]/span[1]\").text\n",
    "    company_name = driver.find_element_by_xpath(f\"//div[@class='jobsearch-SerpJobCard']//div[2]/div[1]/div[1]/a\").text\n",
    "    experience_required = driver.find_element_by_xpath(f\"//div[@class='jobsearch-SerpJobCard']//div[3]/div[2]/span[2]\").text\n",
    "    jobs.append({'Job Title': job_title, 'Job Location': job_location, 'Company Name': company_name, 'Experience Required': experience_required})\n",
    "\n",
    "df = pd.DataFrame(jobs)\n",
    "\n",
    "print(df)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa73f86e",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94933f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import csv\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".t-ZTKy\")))\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for i in range(10):  # Load 10 pages of reviews (100 reviews)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "review_elements = driver.find_elements(By.CSS_SELECTOR, \".t-ZTKy\")\n",
    "for review_element in review_elements:\n",
    "    review = {}\n",
    "    review[\"rating\"] = review_element.find_element(By.CSS_SELECTOR, \"._3LWZlK\").text\n",
    "    review[\"summary\"] = review_element.find_element(By.CSS_SELECTOR, \".review-title\").text\n",
    "    review[\"text\"] = review_element.find_element(By.CSS_SELECTOR, \".review-content span\").text\n",
    "    reviews.append(review)\n",
    "\n",
    "with open(\"iphone11_reviews.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Rating\", \"Summary\", \"Review\"])\n",
    "    for review in reviews:\n",
    "        writer.writerow([review[\"rating\"], review[\"summary\"], review[\"text\"]])\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a3bcb",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966be497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/sneakers/pr?sid=6bo%2Cb5g&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".sneaker-card\")))\n",
    "\n",
    "sneakers = []\n",
    "\n",
    "for i in range(5):  # Scroll 5 times to load more sneakers\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "sneaker_elements = driver.find_elements(By.CSS_SELECTOR, \".sneaker-card\")\n",
    "for sneaker_element in sneaker_elements:\n",
    "    sneaker = {}\n",
    "    brand = sneaker_element.find_element(By.CSS_SELECTOR, \".fKAcLc\").text\n",
    "    description = sneaker_element.find_element(By.CSS_SELECTOR, \".IRpwTa\").text\n",
    "    price = sneaker_element.find_element(By.CSS_SELECTOR, \"._30jeq3\").text\n",
    "    sneaker[\"brand\"] = brand\n",
    "    sneaker[\"description\"] = description\n",
    "    sneaker[\"price\"] = price\n",
    "    sneakers.append(sneaker)\n",
    "\n",
    "for sneaker in sneakers[:100]:\n",
    "    print(f\"Brand: {sneaker['brand']}\")\n",
    "    print(f\"Description: {sneaker['description']}\")\n",
    "    print(f\"Price: {sneaker['price']}\\n\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d7268",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.amazon.in/s?k=laptop&crid=2F62Q1F60H1QX&sprefix=lap%2Caps%2C338&ref=nb_sb_noss_1\")\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".s-result-item\")))\n",
    "\n",
    "i7_filter = driver.find_element_by_xpath(\"//span[contains(text(), 'Intel Core i7')]/ancestor::label[1]\")\n",
    "driver.execute_script(\"arguments[0].click();\", i7_filter)\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.text_to_be_present_in_element((By.CSS_SELECTOR, \".a-section.a-text-center span.a-size-medium\"), \"Intel Core i7\"))\n",
    "\n",
    "laptops = []\n",
    "for i in range(1, 11):\n",
    "    title = driver.find_element_by_xpath(f\"(//span[@class='a-size-medium'][contains(., 'Laptop')])[{i}]/ancestor::div[@class='a-section a-text-center']/a/span\").text\n",
    "    rating = driver.find_element_by_xpath(f\"(//div[@class='a-row a-size-base a-color-base']/a/span)[{i}]\").text\n",
    "    price = driver.find_element_by_xpath(f\"(//span[@class='a-price']/span[@class='a-offscreen'])[{i}]\").text\n",
    "    laptops.append({'title': title, 'rating': rating, 'price': price})\n",
    "\n",
    "for laptop in laptops:\n",
    "    print(f\"Title: {laptop['title']}, Rating: {laptop['rating']}, Price: {laptop['price']}\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c991b",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e93981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//a[@href='/top-quotes/']\"))).click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".quoteText\")))\n",
    "\n",
    "quotes = []\n",
    "\n",
    "for quote in driver.find_elements_by_css_selector(\".quoteText\"):\n",
    "    author = quote.find_element_by_xpath(\"./following-sibling::span[@class='author']\").text\n",
    "    type_of_quote = quote.find_element_by_xpath(\"./preceding-sibling::span[@class='quoteCategories']\").text\n",
    "    quotes.append({'quote': quote.text, 'author': author, 'type_of_quote': type_of_quote})\n",
    "\n",
    "for i in range(1000):\n",
    "    print(f\"{quotes[i]['quote']} - {quotes[i]['author']} ({quotes[i]['type_of_quote']})\")\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
